{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40e4fbc-bcbd-4e96-82b8-9fed6dadb878",
   "metadata": {},
   "source": [
    "# NIFTY50 Stock Summary (Table 1)\n",
    "\n",
    "### ðŸŽ¯ Objective\n",
    "In this notebook, we will:\n",
    "1. Scrape **NIFTY50 stock summary** from Yahoo Finance.\n",
    "2. Save the **raw dataset** in `/data/raw/`.\n",
    "3. Clean and standardize the dataset:\n",
    "   - Normalize column names\n",
    "   - Convert numeric columns\n",
    "   - Handle missing values\n",
    "4. Save the **cleaned dataset** in `/data/cleaned/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1005a-f23a-430c-81c1-325ff517e64e",
   "metadata": {},
   "source": [
    "----\n",
    "## Starting with Phase 1\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd630fa-a8ec-4b83-b43d-95e7543d5e3e",
   "metadata": {},
   "source": [
    "## Step 1: Setup Directories and Import Libraries\n",
    "\n",
    "We begin by importing Python libraries and creating dedicated directories to keep our raw data and cleaned data organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2828f8c-dac2-4006-b1a3-1c75fb020361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "os.makedirs(\"../data/cleaned\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19497c0-957f-403d-b58b-3aba8ddcc9f9",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve Raw Data from NSE API\n",
    "\n",
    "The NSE India API provides structured JSON data of NIFTY 50 constituents.\n",
    "We send a request with a browser-like User-Agent header to prevent the server from blocking our request.\n",
    "\n",
    "URL: https://www.nseindia.com/market-data/live-equity-market?symbol=NIFTY%2050\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c001b85-23a1-43fb-8009-b2af2d157f5a",
   "metadata": {},
   "source": [
    "print(\"Status:\", response.status_code)\n",
    "print(\"Content-Type:\", response.headers.get(\"Content-Type\"))\n",
    "print(\"First 500 chars:\\n\", response.text[:500])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "573e249f-3479-4b4f-88c3-3b7e4e564c9c",
   "metadata": {},
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Start session\n",
    "session = requests.Session()\n",
    "\n",
    "# Headers (important: must look like a browser)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.nseindia.com/\",\n",
    "    \"Connection\": \"keep-alive\"\n",
    "}\n",
    "\n",
    "# Step 2: Load NSE homepage (sets cookies in session)\n",
    "session.get(\"https://www.nseindia.com\", headers=headers, timeout=10)\n",
    "\n",
    "# Step 3: Fetch NIFTY 50 stock summary\n",
    "url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050\"\n",
    "response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "# Debugging: check if response is really JSON\n",
    "print(\"Response Content-Type:\", response.headers.get(\"Content-Type\"))\n",
    "print(\"First 200 chars of response:\", response.text[:200])\n",
    "\n",
    "# Step 4: Parse JSON\n",
    "data_json = response.json()  # This will only work if JSON is returned\n",
    "records = data_json.get(\"data\", [])\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434f3a5e-7520-4250-9cd9-68d1321b2759",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m headers = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMozilla/5.0 (Windows NT 10.0; Win64; x64) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     )\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m response = requests.get(url, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure the request was successful\u001b[39;00m\n\u001b[32m     13\u001b[39m data_json = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050\"\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()  # Ensure the request was successful\n",
    "data_json = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260b924-2114-441c-80f0-dd87c50b042a",
   "metadata": {},
   "source": [
    "## Step 3: Save Raw JSON for Reference\n",
    "\n",
    "Itâ€™s good practice to store the raw unmodified data for traceability.\n",
    "This ensures we always have the original source if something goes wrong in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b621326-bd14-4af8-83c3-bbccecdb8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/stock_summary_raw.json\", \"w\") as f:\n",
    "    f.write(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21eaaa-886f-4c19-ac2b-283e10ad6cc1",
   "metadata": {},
   "source": [
    "## Step 4: Parse JSON into a DataFrame\n",
    "\n",
    "The raw JSON contains a key \"data\" where all stock information is stored.\n",
    "We will extract it and convert it into a structured pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082148b3-a31b-495b-8133-c69c6a4128e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\requests\\models.py:976\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data_json = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m records = data_json.get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m      3\u001b[39m df_raw = pd.DataFrame(records)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\requests\\models.py:980\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "records = data_json.get(\"data\", [])\n",
    "df_raw = pd.DataFrame(records)\n",
    "\n",
    "print(\"Raw columns:\", df_raw.columns)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f52ac-5fc3-45f9-978e-605dbeee4167",
   "metadata": {},
   "source": [
    "## Step 5: Save Raw CSV Snapshot\n",
    "\n",
    "Along with JSON, we save the raw CSV to make it easier for analysts who prefer working directly with tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3155e-3d89-48b5-ad12-3291bbce881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv(\"../data/raw/stock_summary_raw.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8689e-af9a-4be2-a30f-64f43347e502",
   "metadata": {},
   "source": [
    "## Step 6: Clean and Standardize Column Names\n",
    "\n",
    "Raw column names may contain spaces, mixed cases, and special characters.\n",
    "We will normalize column names to lowercase, snake_case, and align them with our project schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f045df11-53a2-4be5-8958-23c23feeae2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdf_raw\u001b[49m.copy()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Normalize column names\u001b[39;00m\n\u001b[32m      4\u001b[39m df.columns = (\n\u001b[32m      5\u001b[39m     df.columns.str.strip()\n\u001b[32m      6\u001b[39m     .str.lower()\n\u001b[32m      7\u001b[39m     .str.replace(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     .str.replace(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[^a-z0-9_]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# Rename selected fields to standard names\n",
    "rename_map = {\n",
    "    \"symbol\": \"symbol\",\n",
    "    \"lastprice\": \"last_price\",\n",
    "    \"change\": \"change\",\n",
    "    \"pchange\": \"perc_change\",\n",
    "    \"open\": \"open\",\n",
    "    \"totaltradedvolume\": \"volume\",\n",
    "    \"totaltradedvalue\": \"value\",\n",
    "    \n",
    "    # Additional mappings\n",
    "    \"dayhigh\": \"high\",\n",
    "    \"daylow\": \"low\",\n",
    "    \"previousclose\": \"prev_close\",\n",
    "    \"ffmc\": \"ffmc\",\n",
    "    \"yearhigh\": \"year_high\",\n",
    "    \"yearlow\": \"year_low\",\n",
    "    \"stockindcloseprice\": \"index_close_price\",\n",
    "    \"lastupdatetime\": \"last_update\",\n",
    "    \"nearwkh\": \"near_week_high\",\n",
    "    \"nearwkl\": \"near_week_low\",\n",
    "    \"perchange365d\": \"perc_change_365d\",\n",
    "    \"date365dago\": \"date_365d_ago\",\n",
    "    \"chart365dpath\": \"chart_365d_path\",\n",
    "    \"date30dago\": \"date_30d_ago\",\n",
    "    \"perchange30d\": \"perc_change_30d\",\n",
    "    \"chart30dpath\": \"chart_30d_path\",\n",
    "    \"charttodaypath\": \"chart_today_path\",\n",
    "    \"series\": \"series\",\n",
    "    \"meta\": \"meta\"\n",
    "\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fe661-980a-49d1-a75e-fff0afa1814c",
   "metadata": {},
   "source": [
    "## Step 7: Convert Numerical Columns\n",
    "\n",
    "By default, some fields may be stored as strings.\n",
    "We will explicitly convert them into numeric values for proper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26591e4-3ef3-451d-968e-0e4258dc4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"last_price\", \"change\", \"perc_change\", \"open\", \"high\", \"low\", \"volume\", \"value\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b0688-d169-4656-b71d-e61c7706b476",
   "metadata": {},
   "source": [
    "## Step 8: Handle Missing Values\n",
    "\n",
    "To ensure data quality, we will handle missing values by:\n",
    "\n",
    "Dropping rows where the stock symbol is missing.\n",
    "\n",
    "Filling missing numerical fields with the median value of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6877ee2-f748-46a1-b29c-7c4671b683ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop invalid rows\n",
    "df = df.dropna(subset=[\"symbol\"])\n",
    "\n",
    "# Fill missing numeric fields\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8540b11-986a-493b-8f63-3375fe3026ae",
   "metadata": {},
   "source": [
    "### Further cleaning and standardising \n",
    "\n",
    "* Check the column headers to determine if further standardisation is required.\n",
    "* Check for more missing values and replace them with a default  or a  suitable value.\n",
    "* Check the datatypes of each date & time-specific column. If it's a string, convert it to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccc782-cf91-4d0a-9a12-e3e2dec90521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the column headers\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338e203-dc64-4c68-aee4-62806c85e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.loc[8, 'perc_change_365d']) => Null\n",
    "df.loc[8, 'perc_change_365d'] = 0\n",
    "print(df.loc[8, 'perc_change_365d'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d251e-9f7b-4886-bc3a-28e607d1c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[8, 'date_365d_ago'])\n",
    "df.loc[8, 'date_365d_ago'] = '05-Sep-2024'\n",
    "print(df.loc[8, 'date_365d_ago'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095896b-201c-46d5-8541-1f33cfba2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[8, 'chart_365d_path'] = 'Missing.svg'\n",
    "print(df.loc[8, 'chart_365d_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101c7b9-64e4-4720-b735-3f431ff98f24",
   "metadata": {},
   "source": [
    "#### Check for the datatype of date or time-specific columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b1d96-6e8d-478b-9f5e-887e7e4be46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type('last_update'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf053ee-c245-49f4-a669-d77346eece52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type('date_30d_ago'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8d84f-d433-44c4-b65f-d1084e2ff359",
   "metadata": {},
   "source": [
    "#### Before conversion make sure all missing values are dealt with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab677a6f-9cc2-46bb-9893-331206e2493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first non-null value from last_update\n",
    "last_update_value = df[\"last_update\"].dropna().iloc[0]\n",
    "\n",
    "# Fill all missing values with this timestamp\n",
    "df[\"last_update\"] = df[\"last_update\"].fillna(last_update_value)\n",
    "\n",
    "# Quick check\n",
    "df[\"last_update\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee3fa8-aa1b-4eaf-adcf-80bfefee9366",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[8, 'last_update'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608bd3f3-2cfb-4514-8ff0-9abc6d5298b1",
   "metadata": {},
   "source": [
    "#### After dealing with the missing values now convert their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a11365-5754-4fa0-bb28-50c81763648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date columns\n",
    "date_cols = [\"last_update\", \"date_365d_ago\", \"date_30d_ago\"]\n",
    "\n",
    "# Convert string â†’ datetime\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "# Verify conversions\n",
    "df.dtypes[[\"last_update\", \"date_365d_ago\", \"date_30d_ago\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afafc4ba-377e-4f50-9994-32c221ff5c96",
   "metadata": {},
   "source": [
    "## Step 9: Save the Final Cleaned Dataset\n",
    "\n",
    "Finally, we save the cleaned dataset which is ready for analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49519715-6e53-45e3-92d9-36bc71fba6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/cleaned/indstock_summary_cleaned.csv\", index=False)\n",
    "print(\"âœ… Cleaned dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a3949-54c1-483c-9eab-63a2bd23af9c",
   "metadata": {},
   "source": [
    "----\n",
    "## Starting with Phase 2\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a83cb-4725-44cb-ae72-26855bc5bec8",
   "metadata": {},
   "source": [
    "## Step 10: Now Extract The Meta Column\n",
    "\n",
    "We will save the `meta` column dataset into `../data/raw`, naming it `indstock_metadata.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6b7d90-7db3-488a-bd2f-2cf8f4e133dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' from 'C:\\Users\\paula\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mast\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# âœ… Step 1: Load your cleaned stock summary file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py:151\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    134\u001b[39m     concat,\n\u001b[32m    135\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m     qcut,\n\u001b[32m    148\u001b[39m )\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[32m    156\u001b[39m     ExcelFile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m     read_spss,\n\u001b[32m    185\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\testing.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPublic testing utility functions.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     assert_extension_array_equal,\n\u001b[32m      8\u001b[39m     assert_frame_equal,\n\u001b[32m      9\u001b[39m     assert_index_equal,\n\u001b[32m     10\u001b[39m     assert_series_equal,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_extension_array_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_frame_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_series_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_index_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\_testing\\__init__.py:405\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytest\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest.raises(expected_exception, match=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m cython_table = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m.common._cython_table.items()\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[33;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[33;03m    keys and expected result.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' from 'C:\\Users\\paula\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# âœ… Step 1: Load your cleaned stock summary file\n",
    "df = pd.read_csv(\"../data/cleaned/indstock_summary_cleaned.csv\")\n",
    "\n",
    "# âœ… Step 2: Drop rows where 'meta' is empty\n",
    "df_meta = df.dropna(subset=[\"meta\"]).copy()\n",
    "\n",
    "# âœ… Step 3: Convert 'meta' string into Python dictionary\n",
    "df_meta[\"meta_dict\"] = df_meta[\"meta\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# âœ… Step 4: Expand the dictionary into separate columns\n",
    "meta_expanded = pd.json_normalize(df_meta[\"meta_dict\"])\n",
    "\n",
    "# âœ… Step 5: Keep symbol + metadata together\n",
    "meta_final = pd.concat([df_meta[[\"symbol\"]].reset_index(drop=True),\n",
    "                        meta_expanded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# âœ… Step 6: Save as new CSV file\n",
    "meta_final.to_csv(\"../data/raw/indstock_metadata.csv\", index=False)\n",
    "\n",
    "print(\"Metadata extracted and saved to 'indstock_metadata.csv'\")\n",
    "print(meta_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d5c8e-2812-478b-b6e9-6b2ed0fa1221",
   "metadata": {},
   "source": [
    "####  Check for the Column heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573f7c8f-4b57-4484-9ef5-2a2e1e634e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmeta_final\u001b[49m.columns\n",
      "\u001b[31mNameError\u001b[39m: name 'meta_final' is not defined"
     ]
    }
   ],
   "source": [
    "meta_final.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce102c8-70bf-462a-a26d-57cab0c999e7",
   "metadata": {},
   "source": [
    "## Step 11: Standardisation of Column Header Name \n",
    "\n",
    "Rename column header into a uniform pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2e7cd8-6286-4aae-b4b5-21258770f01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' from 'C:\\Users\\paula\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load file\u001b[39;00m\n\u001b[32m      4\u001b[39m df_meta = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/indstock_metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py:151\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    134\u001b[39m     concat,\n\u001b[32m    135\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m     qcut,\n\u001b[32m    148\u001b[39m )\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[32m    156\u001b[39m     ExcelFile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m     read_spss,\n\u001b[32m    185\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\testing.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mPublic testing utility functions.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     assert_extension_array_equal,\n\u001b[32m      8\u001b[39m     assert_frame_equal,\n\u001b[32m      9\u001b[39m     assert_index_equal,\n\u001b[32m     10\u001b[39m     assert_series_equal,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_extension_array_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_frame_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_series_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massert_index_equal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\_testing\\__init__.py:405\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytest\u001b[39;00m\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest.raises(expected_exception, match=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m cython_table = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m.common._cython_table.items()\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[32m    409\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[33;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[33;03m    keys and expected result.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' from 'C:\\Users\\paula\\Documents\\My Workspace\\Projects\\IndianStockAnalysis\\.env_ind_stock\\Lib\\site-packages\\pandas\\__init__.py' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file\n",
    "df_meta = pd.read_csv(\"../data/raw/indstock_metadata.csv\")\n",
    "\n",
    "# Define rename mapping\n",
    "rename_map = {\n",
    "    \"companyName\": \"company_name\",\n",
    "    \"industry\": \"industry\",\n",
    "    \"activeSeries\": \"active_series\",\n",
    "    \"debtSeries\": \"debt_series\",\n",
    "    \"isFNOSec\": \"is_fno_sec\",\n",
    "    \"isCASec\": \"is_ca_sec\",\n",
    "    \"isSLBSec\": \"is_slb_sec\",\n",
    "    \"isDebtSec\": \"is_debt_sec\",\n",
    "    \"isSuspended\": \"is_suspended\",\n",
    "    \"tempSuspendedSeries\": \"temp_suspended_series\",\n",
    "    \"isETFSec\": \"is_etf_sec\",\n",
    "    \"isDelisted\": \"is_delisted\",\n",
    "    \"isin\": \"isin\",\n",
    "    \"slb_isin\": \"slb_isin\",\n",
    "    \"listingDate\": \"listing_date\",\n",
    "    \"isMunicipalBond\": \"is_municipal_bond\",\n",
    "    \"isHybridSymbol\": \"is_hybrid_symbol\",\n",
    "    \"quotepreopenstatus.equityTime\": \"equity_time\",\n",
    "    \"quotepreopenstatus.preOpenTime\": \"pre_open_time\",\n",
    "    \"quotepreopenstatus.QuotePreOpenFlag\": \"quote_pre_open_flag\",\n",
    "}\n",
    "\n",
    "# Apply rename\n",
    "df_meta = df_meta.rename(columns=rename_map)\n",
    "\n",
    "# Remove duplicate \"symbol\" column if needed\n",
    "df_meta = df_meta.loc[:, ~df_meta.columns.duplicated()]\n",
    "\n",
    "# Save cleaned file\n",
    "df_meta.to_csv(\"../data/cleaned/indstock_metadata_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Standardized metadata saved as 'indstock_metadata_cleaned.csv'\")\n",
    "print(df_meta.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cb2d4-cddb-490b-a09e-18b013135b4a",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22c69b-070d-4504-88ff-9a38f949e8c2",
   "metadata": {},
   "source": [
    "## ðŸ“Š Conclusion\n",
    "\n",
    "We have successfully:\n",
    "* Extracted the complete stock summary of all NIFTY 50 constituents.\n",
    "* Organized the workflow into raw and cleaned datasets.\n",
    "* Ensured numerical consistency and handled missing values.\n",
    "\n",
    "This cleaned dataset can now be directly used for:\n",
    "* **Exploratory Data Analysis (EDA)**\n",
    "* **Visualization Dashboards**\n",
    "* **Integration into larger financial projects**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
